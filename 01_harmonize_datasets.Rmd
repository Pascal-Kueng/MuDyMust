---
title: "MuDyMust - Harmonize Datasets"
author: "Küng, P., Höhener, P.S., Vieth, G., Spliesgart, A., Scholz, U., Rothman, A., Simpson, J."
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    theme: flatly
    df_print: kable
    toc: yes
    toc_float:
      collapsed: false
      smooth_scroll: true
    code_folding: show
    toc_depth: 5
    highlight: tango
---

```{r setup, message = FALSE, warning = FALSE, results = 'hide'}

library(tidyverse)
library(easystats)
library(haven)
library(bmlm)

```


# Load Datasets

```{r}

df_kamp <- haven::read_sav('Datasets/KAMP_full.sav') 
# only select the correct days
df_kamp <- df_kamp[df_kamp$day_ent >= 0,] 

df_tt <- readRDS('Datasets/t&t.rds') 

```


# Harmonize Measures

Function that renames measures and puts them on the same scale. 

```{r}

global_required_predictors <- c("emo_support", "pract_support", "pos_control", "neg_control")

rescale_measures <- function(
  data, 
  day,
  id,
  mvpa,
  dyad_type, 
  predictors, 
  
  required_predictors = global_required_predictors,
  original_scale = "auto", 
  new_scale = c(0, 5)
) {

  # Check that all required predictors are specified
  missing_predictors <- setdiff(required_predictors, names(predictors))
  if (length(missing_predictors) > 0) {
    stop("Missing predictors in mapping: ", paste(missing_predictors, collapse = ", "))
  }
  
  # Create a standardized data frame with key variables
  standardized_data <- data.frame(
    id = data[[id]],
    day = data[[day]],
    mvpa = data[[mvpa]],
    dyad_type = data[[dyad_type]],
    stringsAsFactors = FALSE
  )
  
  # Process each predictor: if the mapping is NA, create a column of NA; otherwise, use the column from the data
  for (pred in names(predictors)) {
    col_name <- predictors[[pred]]
    if (is.na(col_name)) {
      standardized_data[[pred]] <- NA
    } else {
      if (!col_name %in% names(data)) {
        stop(paste("Column", col_name, "not found in data for predictor", pred))
      }
      standardized_data[[pred]] <- data[[col_name]]
    }
  }
  
  # Helper function to rescale a vector
  rescale_column <- function(x, orig_scale, new_scale) {
    if ("haven_labelled" %in% class(x)) {
      x <- haven::zap_labels(x)
    }
    if (all(is.na(x))) return(x)
    if (identical(orig_scale, "auto")) {
      orig_min <- min(x, na.rm = TRUE)
      orig_max <- max(x, na.rm = TRUE)
    } else if (is.numeric(orig_scale) && length(orig_scale) == 2) {
      orig_min <- orig_scale[1]
      orig_max <- orig_scale[2]
    } else {
      stop("original_scale must be 'auto' or a numeric vector of length 2.")
    }
    if (orig_min == orig_max) {
      warning("Constant variable encountered; replacing with new minimum.")
      return(rep(new_scale[1], length(x)))
    }
    (x - orig_min) / (orig_max - orig_min) * (new_scale[2] - new_scale[1]) + new_scale[1]
  }
  
  # Rescale the predictor columns
  standardized_data <- standardized_data %>% 
    dplyr::mutate(across(all_of(required_predictors), ~ rescale_column(.x, original_scale, new_scale)))
  
  # Ensure correct data types
  standardized_data <- standardized_data %>%
    dplyr::mutate(
      id = as.factor(id),
      day = as.integer(day),
      mvpa = as.integer(mvpa),
      dyad_type = as.factor(dyad_type)
    )
  
  # Order columns: key variables first, then predictors
  standardized_data <- standardized_data[, c("id", "dyad_type", "day", "mvpa", required_predictors)]
  return(standardized_data)
}




```


Apply function to rescale and rename the data

## KAMP
```{r}

# Create Dyad-Type column
df_kamp$dyad_type <- 'Test'

# Apply function to prepare data
df_kamp <- rescale_measures(
  data = df_kamp, 
  day = 'day_ent',
  id = 'IDdiary',
  mvpa = 'TotalMVPA',
  dyad_type = 'dyad_type',
  predictors = c(
    pos_control = "T210_1",
    neg_control = "T211_1",
    emo_support = NA,      # explicitly set to NA if not available
    pract_support = NA     # explicitly set to NA if not available
  )
)

head(df_kamp)

```

```{r}

df_tt$dyad_type <- 'RomanticPartners'
df_tt <- rescale_measures(
  df_tt, 
  day = 'day',
  id = 'userID', #!todo: how to deal with dyadic datasets? Select one person at random?
  mvpa = 'minutes_mvpa_non_filtered', #!todo: use self-report?
  dyad_type = 'dyad_type',
  predictors = c(
    emo_support = 'ss_emo_pleasure', #!todo: which support do we use?
    pract_support = 'ss_inst_prov', 
    pos_control = 'ss_psc_more',
    neg_control = 'ss_nsc_more'
  )
)

head(df_tt)

```


# Combine Datasets and Center within- and between person

Function to combinde datasets provided

```{r}

combine_datasets <- function(..., pred_vars = global_required_predictors){ 
  data_list <- list(...)
  
  for (i in seq_along(data_list)) {
    data_list[[i]]$studyID <- i
  }
  
  combined_df <- dplyr::bind_rows(data_list) %>%
    bmlm::isolate(
      by = "id", 
      value = pred_vars,
      which = "both"
    ) %>%
    dplyr::mutate(
      dplyr::across(where(is.numeric), ~ ifelse(is.nan(.), NA, .)),
      studyID = as.factor(studyID)
    )
  
  return(combined_df)
}



```


Apply function and combine datasets

```{r}

df_merged <- combine_datasets(
  df_kamp,
  df_tt
)

head(df_merged)
head(df_merged[df_merged$studyID == 2,])

```

